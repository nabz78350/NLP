{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import random\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from modelling import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "import random\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modelling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class  = DataClass(use_prediction= True,use_enhanced=\"lstm\",custom=True)\n",
    "data_class.create_dataset()\n",
    "modelling_data = DataModel(data = data_class.data_model,\n",
    "                           use_enhanced= data_class.use_enhanced,\n",
    "                           custom_test_index=data_class.enhanced_index,\n",
    "                           max_len=200,\n",
    "                           custom=True)\n",
    "modelling_data.create_padding()\n",
    "modelling_data.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_name = data_class.freq_name.copy()\n",
    "freq_name = freq_name[freq_name['total']>1000].sort_values(by = 'total')\n",
    "data_model_translate = freq_name[[\"firstname\"]]\n",
    "data_model_translate[\"Y\"] = data_model_translate['firstname']\n",
    "data_model_translate.columns = [\"X\",\"Y\"]\n",
    "data_model_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def alter_word(word):\n",
    "    operations = []\n",
    "    if len(word) < 3:\n",
    "        possible_ops = ['replace_one', 'delete_one']\n",
    "    else:\n",
    "        possible_ops = ['replace_two', 'replace_one', 'delete_one', 'delete_two']\n",
    "\n",
    "    for op in possible_ops:\n",
    "        if op == 'replace_one':\n",
    "            pos = random.randint(0, len(word) - 1)\n",
    "            new_letter = random.choice(string.ascii_letters)\n",
    "            new_word = word[:pos] + new_letter + word[pos + 1:]\n",
    "            new_word = str.lower(new_word)\n",
    "            operations.append(new_word)\n",
    "\n",
    "        elif op == 'replace_two':\n",
    "            pos1, pos2 = random.sample(range(len(word)), 2)\n",
    "            new_letter1, new_letter2 = random.sample(string.ascii_letters, 2)\n",
    "            new_word = list(word)\n",
    "            new_word[pos1], new_word[pos2] = new_letter1, new_letter2\n",
    "            \n",
    "            operations.append(str.lower(''.join(new_word)))\n",
    "\n",
    "        elif op == 'delete_one':\n",
    "            pos = random.randint(0, len(word) - 1)\n",
    "            new_word = word[:pos] + word[pos + 1:]\n",
    "            new_word = str.lower(new_word)\n",
    "            operations.append(new_word)\n",
    "\n",
    "        elif op == 'delete_two':\n",
    "            pos1, pos2 = random.sample(range(len(word)), 2)\n",
    "            new_word = ''.join(letter for i, letter in enumerate(word) if i not in [pos1, pos2])\n",
    "            new_word = str.lower(new_word)\n",
    "            operations.append(new_word)\n",
    "\n",
    "    return operations\n",
    "\n",
    "data = []\n",
    "for ope in tqdm(range(50)):\n",
    "    for index in range(data_model_translate.shape[0]):\n",
    "        name,true =data_model_translate.iloc[index]\n",
    "        altered_name = alter_word(name)   \n",
    "        out = pd.DataFrame([altered_name,[true]*len(altered_name)]).T\n",
    "        data.append(out)\n",
    "    \n",
    "data_model = pd.concat(data,axis=0)\n",
    "data_model.columns = ['X','Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# Tokenize words\n",
    "tokenizer = Tokenizer(num_words=500, oov_token=\"<OOV>\",char_level=True)\n",
    "tokenizer.fit_on_texts(data_model['X'])\n",
    "X_seq = tokenizer.texts_to_sequences(data_model['X'])\n",
    "X_padded = pad_sequences(X_seq, padding='post', maxlen=8)\n",
    "\n",
    "Y_encoded = label_encoder.fit_transform(data_model['Y'])\n",
    "Y_categorical = to_categorical(Y_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_padded, Y_categorical, test_size=0.1, random_state=42)\n",
    "# Assuming your LabelEncoder is named label_encoder and has been fitted\n",
    "\n",
    "# Saving the LabelEncoder\n",
    "# with open('label_encoder.pickle', 'wb') as handle:\n",
    "#     pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(500, 16, input_length=8),\n",
    "    Bidirectional(LSTM(100, return_sequences=True)),\n",
    "    Bidirectional(LSTM(100)),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(Y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    epochs=20,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    validation_split = 0.25,\n",
    "                    callbacks = [early_stopping],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the LabelEncoder\n",
    "with open('label_encoder.pickle', 'rb') as handle:\n",
    "    loaded_label_encoder = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we tokenize and pad the new X_test strings as we did with the training data\n",
    "X_test_new =data_class.data.loc[data_class.enhanced_index]['firstname'].str.lower().values.tolist()\n",
    "X_test_new_seq = tokenizer.texts_to_sequences(X_test_new)\n",
    "X_test_new_padded = pad_sequences(X_test_new_seq, padding='post', maxlen=8)\n",
    "\n",
    "# Then we predict using the trained model\n",
    "predictions_new = model.predict(X_test_new_padded)\n",
    "predicted_classes_new_indices = np.argmax(predictions_new, axis=1)\n",
    "predicted_class_labels_new = label_encoder.inverse_transform(predicted_classes_new_indices)\n",
    "prediction_new_df = pd.DataFrame({\n",
    "    'Original_X_test': X_test_new,\n",
    "    'Predicted_Category': predicted_class_labels_new\n",
    "})\n",
    "data_class  = DataClass(use_prediction= True,use_enhanced=True,custom=True)\n",
    "\n",
    "prediction_new_df['true'] = data_class.data.loc[data_class.enhanced_index]['groundtruth'].values\n",
    "prediction_new_df\n",
    "data_class.data.loc[data_class.enhanced_index,'firstname_lower_lstm'] = predicted_class_labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class.data.loc[data_class.enhanced_index,'firstname_lower_lstm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "choices = data_model['Y'].unique().tolist()\n",
    "all_pred = []\n",
    "for x in X_test_new:\n",
    "    pred = process.extract(x,choices= choices,limit=1)[0][0]\n",
    "    all_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "modifying features\n",
      "['link', 'employer', 'occupation', 'name_sex', 'firstname_lower']\n",
      "['link', 'employer', 'occupation', 'name_sex', 'firstname_lower_lstm']\n",
      "Shape of training tensor:  (205, 200)\n",
      "Shape of testing tensor:  (27, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ch prenom femme ang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>patron prenom femme hermance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ep prenom femme marguerite</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ep prenom femme silvie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>prenom femme angeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>metages prenom homme felix</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>prenom homme george</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>patron prenom femme gilberte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>fr re labrye manoeuvre prenom homme francisque</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>fils prenom homme magloire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>p f prenom femme madeleine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>prenom femme tiennette</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ch prenom homme eug</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>fin lansait enttinateur prenom homme claude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ch san pla prenom homme gilbert</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>prenom femme marthe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>domest lavane prenom homme paul</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>debon menuisier prenom homme jean</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>prenom homme victor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>prenom femme madeleine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>id prenom homme francois</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>chef patron entiinateur prenom homme claude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>pr prenom femme madeleine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>coiffeur p prenom homme th odore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>chef eublinat prenom femme berthe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>chef prenom homme omer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>sans mof prenom femme petronille</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            message  label\n",
       "18                              ch prenom femme ang      1\n",
       "24                     patron prenom femme hermance      1\n",
       "25                       ep prenom femme marguerite      0\n",
       "34                           ep prenom femme silvie      0\n",
       "65                            prenom femme angeline      1\n",
       "69                       metages prenom homme felix      1\n",
       "82                              prenom homme george      1\n",
       "104                    patron prenom femme gilberte      1\n",
       "121  fr re labrye manoeuvre prenom homme francisque      1\n",
       "126                      fils prenom homme magloire      1\n",
       "132                      p f prenom femme madeleine      0\n",
       "138                          prenom femme tiennette      0\n",
       "142                             ch prenom homme eug      1\n",
       "147     fin lansait enttinateur prenom homme claude      1\n",
       "159                 ch san pla prenom homme gilbert      1\n",
       "193                             prenom femme marthe      0\n",
       "197                 domest lavane prenom homme paul      0\n",
       "200               debon menuisier prenom homme jean      1\n",
       "216                             prenom homme victor      1\n",
       "217                          prenom femme madeleine      0\n",
       "219                        id prenom homme francois      0\n",
       "225     chef patron entiinateur prenom homme claude      1\n",
       "231                       pr prenom femme madeleine      0\n",
       "232                coiffeur p prenom homme th odore      1\n",
       "233               chef eublinat prenom femme berthe      1\n",
       "234                          chef prenom homme omer      1\n",
       "236                sans mof prenom femme petronille      0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 \n",
    "from modelling import *\n",
    "data_class  = DataClass(use_prediction= True,use_enhanced=\"lstm\",custom=True)\n",
    "data_class.create_dataset()\n",
    "modelling_data = DataModel(data = data_class.data_model,\n",
    "                           use_enhanced= data_class.use_enhanced,\n",
    "                           custom_test_index=data_class.enhanced_index,\n",
    "                           max_len=200,\n",
    "                           custom=True)\n",
    "modelling_data.create_padding()\n",
    "modelling_data.test\n",
    "data_class.data_model.loc[data_class.enhanced_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 - 3s - loss: 1.0968 - accuracy: 0.4573 - val_loss: 0.8198 - val_accuracy: 0.3659 - 3s/epoch - 454ms/step\n",
      "Epoch 2/200\n",
      "6/6 - 1s - loss: 0.7451 - accuracy: 0.5549 - val_loss: 0.6541 - val_accuracy: 0.6341 - 1s/epoch - 192ms/step\n",
      "Epoch 3/200\n",
      "6/6 - 2s - loss: 0.7104 - accuracy: 0.4939 - val_loss: 0.7058 - val_accuracy: 0.3659 - 2s/epoch - 262ms/step\n",
      "Epoch 4/200\n",
      "6/6 - 1s - loss: 0.6988 - accuracy: 0.5793 - val_loss: 0.6051 - val_accuracy: 0.6341 - 1s/epoch - 218ms/step\n",
      "Epoch 5/200\n",
      "6/6 - 1s - loss: 0.6119 - accuracy: 0.7012 - val_loss: 0.5352 - val_accuracy: 0.9268 - 1s/epoch - 226ms/step\n",
      "Epoch 6/200\n",
      "6/6 - 1s - loss: 0.4932 - accuracy: 0.8415 - val_loss: 0.5001 - val_accuracy: 0.8049 - 1s/epoch - 218ms/step\n",
      "Epoch 7/200\n",
      "6/6 - 1s - loss: 0.3240 - accuracy: 0.9024 - val_loss: 0.2319 - val_accuracy: 0.9268 - 1s/epoch - 213ms/step\n",
      "Epoch 8/200\n",
      "6/6 - 1s - loss: 0.1164 - accuracy: 0.9756 - val_loss: 0.1606 - val_accuracy: 0.9268 - 1s/epoch - 212ms/step\n",
      "Epoch 9/200\n",
      "6/6 - 1s - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9268 - 1s/epoch - 229ms/step\n",
      "Epoch 10/200\n",
      "6/6 - 1s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9268 - 1s/epoch - 224ms/step\n",
      "Epoch 11/200\n",
      "6/6 - 1s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9512 - 1s/epoch - 213ms/step\n",
      "Epoch 12/200\n",
      "6/6 - 1s - loss: 8.0861e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9512 - 1s/epoch - 235ms/step\n",
      "Epoch 13/200\n",
      "6/6 - 1s - loss: 5.7351e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9512 - 1s/epoch - 222ms/step\n",
      "Epoch 14/200\n",
      "6/6 - 1s - loss: 6.2624e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9268 - 1s/epoch - 216ms/step\n",
      "Epoch 15/200\n",
      "6/6 - 1s - loss: 1.5685e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9268 - 1s/epoch - 230ms/step\n",
      "Epoch 16/200\n",
      "6/6 - 1s - loss: 1.4500e-04 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9268 - 1s/epoch - 200ms/step\n",
      "Epoch 17/200\n",
      "6/6 - 1s - loss: 6.2337e-05 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9268 - 1s/epoch - 212ms/step\n",
      "Epoch 18/200\n",
      "6/6 - 1s - loss: 5.5883e-05 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9268 - 1s/epoch - 212ms/step\n",
      "1/1 - 0s - loss: 0.0846 - accuracy: 0.9854 - 130ms/epoch - 130ms/step\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.4532 - accuracy: 0.7407\n",
      "1/1 [==============================] - 0s 133ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_socface \u001b[38;5;241m=\u001b[39m Model(data \u001b[38;5;241m=\u001b[39m modelling_data,model_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model_socface\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel_socface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model_socface\u001b[38;5;241m.\u001b[39mcompute_results()\n\u001b[0;32m      5\u001b[0m model_socface\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtable_results\n",
      "File \u001b[1;32mc:\\Users\\marti\\Documents\\NLP\\modelling.py:526\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marti\\Documents\\NLP\\modelling.py:459\u001b[0m, in \u001b[0;36mMLPModel.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracy_test \u001b[38;5;241m=\u001b[39m test_dense_results[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m \n\u001b[0;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\u001b[43my_pred\u001b[49m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_results\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRUE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRED\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "model_socface = Model(data = modelling_data,model_name= \"mlp\")\n",
    "model_socface.fit()\n",
    "model_socface.predict()\n",
    "model_socface.compute_results()\n",
    "model_socface.model.table_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
